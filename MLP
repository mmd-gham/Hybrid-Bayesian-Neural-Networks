import tensorflow as tf
from tf_keras.models import Sequential
from tf_keras.layers import Dense, InputLayer, LayerNormalization
from tf_keras.losses import SparseCategoricalCrossentropy
import tensorflow.keras.backend as K
from tf_keras.callbacks import TensorBoard, EarlyStopping
from tf_keras.optimizers import Adam
from tf_keras import regularizers
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score
import numpy as np
import pandas as pd
import time
import matplotlib.pyplot as plt
from imblearn.over_sampling import KMeansSMOTE
import datetime




def nll(y_true, y_pred):
    eps = 1e-10  # Prevent log(0)
    return -K.mean(K.sum(y_true * K.log(y_pred + eps), axis=-1))


MLP = Sequential([
    InputLayer(input_shape=(1000,)),

    Dense(256, activation='swish', bias_regularizer=regularizers.L2(1e-4)),
    Dense(128, activation='swish', bias_regularizer=regularizers.L2(1e-4)),
    Dense(128, activation='swish', bias_regularizer=regularizers.L2(1e-4)),

    LayerNormalization(epsilon=1e-6),


    Dense(31, activation='softmax'),
])


MLP.compile(loss=nll,
              optimizer= Adam(0.0001),
              metrics=['accuracy'],
              experimental_run_tf_function=False)

MLP.summary()


# Callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)
log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)


#Training
start_time = time.time()
history = MLP.fit(X_train, y_train_oh,
                    epochs=30,
                    batch_size=32,
                    validation_data=(X_val, y_val_oh),
                    callbacks=[tensorboard_callback, early_stopping],
                    verbose=1)

end_time = time.time()
training_time = end_time - start_time
print(f"Training time: {training_time:.2f} seconds")



# Plot the training and validation curves
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.show()




y_pred = MLP.predict(X_test)
y_pred_labels = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test_oh, axis=1)


recall = recall_score(y_true, y_pred_labels, average='weighted')
precision = precision_score(y_true, y_pred_labels, average='weighted')
f1 = f1_score(y_true, y_pred_labels, average='weighted')
accuracy = accuracy_score(y_true, y_pred_labels)

print(f"Recall: {recall}")
print(f"Precision: {precision}")
print(f"F1 Score: {f1}")
print(f"Accuracy: {accuracy}")




%load_ext tensorboard
%tensorboard --logdir logs/fit
